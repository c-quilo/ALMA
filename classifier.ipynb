{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Unique values in new_catalysis_type:\n",
      "['bio' 'not_catalysis' 'electro' 'organo' 'hetero' 'photo' 'homo'\n",
      " 'unknown']\n",
      "\n",
      "âœ… Unique values in new_application_theme:\n",
      "['co2 utilisation' 'biomass' 'unknown' 'water' 'ammonium' 'enzyme'\n",
      " 'methane']\n",
      "\n",
      "âœ… Unique values in standard_class:\n",
      "['hard_negative' 'hard_positive' 'soft_positive' 'soft_negative'\n",
      " 'background']\n",
      "\n",
      "âœ… Unique values in cited_by_patent:\n",
      "['unknown' 'TRUE' 'FALSE']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load metadata\n",
    "file_path = \"./goldstandardPapers/reclassified_papers_checkpoint.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Load embeddings\n",
    "embeddings_path = \"specter2_reclassified.npy\"\n",
    "embeddings = np.load(embeddings_path)\n",
    "\n",
    "# Check label categories\n",
    "columns_to_check = [\"new_catalysis_type\", \"new_application_theme\", \"standard_class\", \"cited_by_patent\"]\n",
    "\n",
    "for col in columns_to_check:\n",
    "    print(f\"\\nUnique values in {col}:\")\n",
    "    print(df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data split: 3083 train samples, 771 test samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode categorical labels\n",
    "label_encoders = {}\n",
    "for col in columns_to_check:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])  # Convert to numeric\n",
    "    label_encoders[col] = le  # Store encoder for later\n",
    "\n",
    "# Define input (X) and output (y)\n",
    "X = embeddings\n",
    "y = df[columns_to_check].values  # Multi-label target\n",
    "\n",
    "# Split into train/test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nData split: {X_train.shape[0]} train samples, {X_test.shape[0]} test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Model training complete!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "# Initialize base model\n",
    "base_model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "# Multi-output classifier\n",
    "multi_clf = MultiOutputClassifier(base_model)\n",
    "multi_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n Model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Classification report for new_catalysis_type:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       107\n",
      "           1       0.87      0.75      0.80       110\n",
      "           2       0.69      0.84      0.75       209\n",
      "           3       0.63      0.68      0.65       106\n",
      "           4       0.64      0.53      0.58        78\n",
      "           5       0.58      0.38      0.46        47\n",
      "           6       0.90      0.74      0.81       111\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.74       771\n",
      "   macro avg       0.64      0.61      0.62       771\n",
      "weighted avg       0.74      0.74      0.74       771\n",
      "\n",
      "\n",
      " Classification report for new_application_theme:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        23\n",
      "           1       0.66      0.52      0.58        93\n",
      "           2       0.67      0.40      0.50        87\n",
      "           3       0.83      0.86      0.85       125\n",
      "           4       0.80      0.13      0.23        30\n",
      "           5       0.68      0.82      0.74       253\n",
      "           6       0.63      0.81      0.71       160\n",
      "\n",
      "    accuracy                           0.69       771\n",
      "   macro avg       0.61      0.51      0.52       771\n",
      "weighted avg       0.68      0.69      0.66       771\n",
      "\n",
      "\n",
      " Classification report for standard_class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.44      0.48       287\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.80      0.46      0.59        97\n",
      "           4       0.58      0.75      0.65       375\n",
      "\n",
      "    accuracy                           0.58       771\n",
      "   macro avg       0.38      0.33      0.34       771\n",
      "weighted avg       0.58      0.58      0.57       771\n",
      "\n",
      "\n",
      " Classification report for cited_by_patent:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.94      0.78       489\n",
      "           1       0.61      0.17      0.26       278\n",
      "           2       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.66       771\n",
      "   macro avg       0.42      0.37      0.35       771\n",
      "weighted avg       0.64      0.66      0.59       771\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ALMA/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/ALMA/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/ALMA/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/ALMA/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/ALMA/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/ALMA/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/ALMA/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/ALMA/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/ALMA/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/ALMA/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/ALMA/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/ALMA/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = multi_clf.predict(X_test)\n",
    "\n",
    "# Evaluate each output separately\n",
    "for i, col in enumerate(columns_to_check):\n",
    "    print(f\"\\n Classification report for {col}:\")\n",
    "    print(classification_report(y_test[:, i], y_pred[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_new_papers(new_embeddings):\n",
    "    \"\"\"\n",
    "    Takes new embeddings as input and predicts the 4 classification labels.\n",
    "    \"\"\"\n",
    "    predictions = multi_clf.predict(new_embeddings)\n",
    "\n",
    "    # Convert numerical labels back to categorical values\n",
    "    decoded_predictions = {}\n",
    "    for i, col in enumerate(columns_to_check):\n",
    "        decoded_predictions[col] = label_encoders[col].inverse_transform(predictions[:, i])\n",
    "\n",
    "    return decoded_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ Predicted new_catalysis_type: ['not_catalysis' 'not_catalysis' 'not_catalysis']\n",
      "\n",
      "ðŸ“Œ Predicted new_application_theme: ['unknown' 'unknown' 'unknown']\n",
      "\n",
      "ðŸ“Œ Predicted standard_class: ['soft_positive' 'soft_positive' 'soft_positive']\n",
      "\n",
      "ðŸ“Œ Predicted cited_by_patent: ['FALSE' 'FALSE' 'FALSE']\n"
     ]
    }
   ],
   "source": [
    "# Example: New abstract embeddings (assuming they are already computed)\n",
    "new_paper_embeddings = np.random.rand(3, X.shape[1])  # Dummy data, replace with real embeddings\n",
    "\n",
    "# Predict classification labels\n",
    "results = classify_new_papers(new_paper_embeddings)\n",
    "\n",
    "# Display predictions\n",
    "for col, preds in results.items():\n",
    "    print(f\"\\nðŸ“Œ Predicted {col}: {preds}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ALMA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
